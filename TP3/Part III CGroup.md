# Part III : CGroup

âœ **Les *CGroup* c'est un mÃ©canisme du noyau Linux pour faire des groupes de processus et restreindre leur accÃ¨s aux ressources de la machine.**

On parle ici notamment de restreindre l'accÃ¨s Ã  :

- la mÃ©moire (par exemple : on dÃ©finit une quantitÃ© de mÃ©moire maximum que le groupe de processus aura le droit d'utiliser)
- le CPU (par exemple : on dÃ©finit un poids pour qu'un groupe de processus soit prioritaire)
- Ã©criture/lecture (par exemple : limitation des Ã©critures sur le disque)
- d'autres trucs, c'pour vous donner une idÃ©e

âœ **Les *CGroup* permettent aussi de monitorer en temps rÃ©el l'accÃ¨s aux ressources d'un groupe de processus.**

Vous pouvez constater Ã§a avec les commandes `systemd-cgls` et `systemd-cgtop` notamment.

![Cgroups](./img/cgroup.jpg)

> C'est dessinÃ© par **[Julia Evans](https://jvns.ca/)**, elle a fait plein de ptites illustrations tech de ce genre, je recommande :D

## Sommaire

- [Part III : CGroup](#part-iii--cgroup)
  - [Sommaire](#sommaire)
  - [1. Explore](#1-explore)
  - [2. Do it](#2-do-it)
  - [3. systemd](#3-systemd)
    - [A. One-shot](#a-one-shot)
    - [B. Real service](#b-real-service)

## 1. Explore

Pour rappel : la configuration actuelle des *CGroups* est dispo dans `/sys/fs/cgroup`.

ğŸŒ **Afficher...** :

- la liste des controllers *CGroups* dispos sur le systÃ¨me
- la quantitÃ© de mÃ©moire max que vous Ãªtes autorisÃ©s Ã  utiliser dans votre session utilisateur
- les noms de tous les *CGroups* crÃ©Ã©s
  - ce sont tous les sous-dossiers de `/sys/fs/cgroup`
  - il devrait y avoir au moins les slices et scopes de systemd, on en parle plus bas

## 2. Do it

ğŸŒ **CrÃ©er un nouveau *CGroup*** :

- appelez-le `meow`
- activez les controllers `cpu` `cpuset` et `memory` s'ils ne le sont pas dÃ©jÃ 

> Vous devez donc crÃ©er le dossier `/sys/fs/cgroup/meow/` avec un simple `mkdir`, puis interagir avec les fichiers qui s'y trouvent (le dossier a Ã©tÃ© automatiquement populÃ©).

ğŸŒ **CrÃ©er un nouveau sous-CGroup** :

- appelez-le `task1`
- on parle de crÃ©er le dossier `/sys/fs/cgroup/meow/task1/` 
- prouvez que les controllers activÃ©s sur `meow` ont bien Ã©tÃ© hÃ©ritÃ©s

ğŸŒ **Mettez en place une limitation RAM**

- dÃ©finissez une limite de 150M de RAM pour ce CGroup `task1`

ğŸŒ **Prouvez que la limite est effective**

1. utilisez la commande `stress-ng` pour remplir la mÃ©moire de la machine
2. constatez que la RAM est pleine
3. ajoutez votre shell `bash` actuel au *CGroup* `task1`
4. utilisez de nouveau `stress-ng`
5. constatez que le processus `stress-ng` est tuÃ© en boucle dÃ¨s qu'il remplit la RAM au delÃ  de la limite

> On rappelle que tout processus lancÃ© par un processus existant se retrouvera par dÃ©faut dans le mÃªme *CGroup* que son parent. C'est pour Ã§a que vous ajoutez votre shell `bash` au *CGroup* : tout ce que vous exÃ©cuterez depuis ce `bash` sera exÃ©cutÃ© dans le mÃªme *CGroup* que lui. Ha et le truc qui tue votre processus quand il prendre trop de RAM, c'est le [**OOM-killer**](https://en.wikipedia.org/wiki/Out_of_memory).

![OOM killer](./img/oom_killer.png)

ğŸŒ **CrÃ©er un nouveau sous-*CGroup*** :

- appelez-le `task2`

ğŸŒ **Appliquer des restrictions CPU** :

- utilisez la mÃ©canique de `cpu.weight` pour dÃ©finir des prioritÃ©s diffÃ©rentes Ã  `task1` et `task2`
- utilisez `stress-ng` ou un bon vieux `cat /dev/random` pour lancer un processus CPU-intensive, et pour prouver que la restriction est en place
- pour tester, vous devez :
  - lancer deux shells en mÃªme temps
  - ajouter le premier au *CGroup* `task1`
  - ajouter le deuxiÃ¨me au *CGroup* `task2`
  - dans les deux shells, lancer un processus CPU-intensive
  - constatez avec un `htop` par exemple que les deux processus ne se rÃ©partissent pas Ã©quitablement la puissance du CPU

## 3. systemd

Par dÃ©faut, sous Linux, y'a systemd (ouais encore lui). Il utilise pas mal les *CGroup* nativement. Il fait naturellement deux trucs :

- **il met les `service` dans des `slice`s**
  - crÃ©er un `slice` systemd, c'est juste crÃ©er un cgroup (dont le nom se terminera par `.slice`)
  - tous les `service`s sont forcÃ©ment dans un `slice`
- **il met des programmes lancÃ©s Ã  l'extÃ©rieur (genre des trucs qui sont pas des `services`) dans des `scope`**
  - c'est pareil : un `scope` c'est juste un CGroup crÃ©Ã© automatiquement par systemd, dont le nom se termine par `.scope`
  - Ã§a permet Ã  systemd de gÃ©rer certains processus mÃªme si c'est pas lui qui les lance
  - par exemple quand t'ouvres une session SSH n_n

Bref, l'un des rÃ´les principaux de systemd c'est lancer et gÃ©rer des processus (services). Il est donc tout naturel qu'il utilise les *CGroups* Linux pour mener Ã  bien ce job.

### A. One-shot

Y'a une commande rigolote et parfois pratique qui permet de jouer avec tout Ã§a. Une commande qui permet de crÃ©er un service systÃ¨me temporaire Ã  la volÃ©e en une seule ligne de commande : `systemd-run`.

> Pour plusieurs tests dans le TP, on se servira du serveur Web embarquÃ© par Python. Il se lance en une seule commande, fait des trucs sur le systÃ¨me (serveur web, donc il lit des fichiers, fait des connexions rÃ©seau), c'est parfait pour faire des tests ! Pour le lancer : `python -m http.server 8888`.

ğŸŒ **Lancer un serveur Web Python sous forme de service temporaire**

- avec la commande `python -m http.server <PORT>`
- n'oubliez pas d'ouvrir ce port dans le firewall pour tester
- il faudra le lancer avec la commande `systemd-run` pour en faire un service temporaire
- affichez le `status` du service pour prouver qu'il run

```bash
# lancer un sleep sous la forme d'un service nommÃ© meow_test.service
sudo systemd-run -u meow_test sleep 9999
```

ğŸŒ **Appliquer Ã  la volÃ©e des restrictions**

- avec l'option `-p` de `systemd-run` vous pouvez prÃ©ciser des paramÃ¨tres pour le service
- utilisez le paramÃ¨tre `MemoryMax` pour mettre en place une limite Ã  234M

> En vrai, `systemd-run` est un tool vraiment pratique pour limiter l'accÃ¨s aux ressources d'un process qu'on lance oneshot.

ğŸŒ **Restrictions *CGroup* ?**

- prouvez que la restriction Ã  234M de `systemd-run` est mise en place avec les *CGroups* Linux

> Les montants de RAM chelous c'pour vous permettre de faire des `grep` pour trouver facilement. Attention par contre, les restrictions automatiques appliquÃ©es par systemd sont exprimÃ©es en octets (pas KB ni MB) donc faut faire une ptite multiplication pour le trouver facilement. En l'occurence, un `grep -nri $(( 234 * 1024 * 1024 ))` depuis `/sys/fs/cgroup` fera le taff ;)

### B. Real service

ğŸŒ **CrÃ©ez un service `web.service`**

- habituÃ©s nan ? Faut crÃ©er un fichier dans `/etc/systemd/system/`
- n'oubliez pas de `sudo systemctl daemon-reload` Ã  chaque modification
- ce service doit lancer un serveur web python sur le port 9999/tcp

ğŸŒ **Restriction *CGroup***

- modifier le fichier `web.service` pour inclure des limitations mises en place par des CGroups :
  - mÃ©moire max : 321M
  - limitation d'Ã©criture disque : 1M
  - limitation de lecture disque : 1M
  - limitation CPU : 50% d'utilisation

ğŸŒ **Prouvez que ces restrictions ont Ã©tÃ© mises en place avec les *CGroups***

- en explorant le dossier `/sys/` toujours !
